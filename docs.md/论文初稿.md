## 0 引言

“一带一路”背景下，全球化进程加速，中国和哈萨克斯坦两国的往来也越来越密切，催生了对跨语言信息检索(CLIR)技术的迫切需求。在跨境电子商务、多语种问答等领域，CLIR有着广泛应用前景。简单来说，CLIR是一种文档检索任务，用户用一种语言提交查询，系统通过检索另一种语言的文档来响应。

基于Transformer [46]神经网络的单语预训练语言模型（例如BERT [13]）在英语的即时检索中在文献中的性能得到了很大的提升。例如，几乎所有在MS MARCO段落和文档检索任务中领先的竞争者都依赖于基于Transformer的预训练语言模型。与此同时，多语言语言模型（例如mBERT、XLM和XLM-R）被提出，并且已经被证明在各种跨语言下游任务上表现良好，例如跨语言文本分类、跨语言命名实体识别以及监督/无监督机器翻译。

Sasaki等人提出了一个大型跨语言检索集合，WikiCLIR，基于维基百科页面上的链接外语文章。因为特定语言的维基百科文章主要由本族语言的人编辑，所以WikiCLIR中的跨语言内容质量很高。但相关的判断是基于页面间的相互链接综合生成的。另一方面，Bonifacio等人通过使用神经机器翻译（NMT）模型将MS MARCO中的查询和段落翻译成目标语言，构建了一个多语言段落排名数据集mMARCO。

另外，我们发现，大多数的CLIR研究在进行实验时都没有对模型在中文和哈萨克语任务上进行评测。。。。



本文的主要贡献如下：



## 1 相关工作

### 1.1 跨语言 Ad-hoc 检索

Ad-hoc 检索是信息检索领域的一个重要概念，指的是根据用户的查询需求，在文档集合中实时检索出相关的文档。在这种情况下，系统不依赖于预定义的查询和文档的索引，而是根据用户提供的查询动态地从文档集合中检索出相关的信息。Ad-hoc 检索可以用于各种场景，包括搜索引擎、文档管理系统、数据库查询等。

Ad-hoc 检索的关键挑战之一是理解用户的查询意图，以便检索出最相关的结果。通常，这需要利用信息检索技术中的各种方法，例如文本分析、语义理解、机器学习等，来识别和理解查询的含义，然后将其映射到文档集合中。常见的 Ad-hoc 检索方法包括基于关键词的检索、基于向量空间模型的检索、基于语义相似度的检索等。

### 1.2 预训练语言模型用于信息检索的范式

预训练语言模型已经为人类语言技术领域带来了一场革命。我们以BERT为例。将BERT应用于即时检索有两种主要方法：(i) 单塔：将查询-文档对打包成一个序列，由一个[sep]标记分隔，然后输入到一个BERT编码器中。在编码期间，每个查询/文档标记都可以关注整个序列（也称为交叉注意力）。我们采用标记的输出表示来预测排名分数；以及(ii) 双塔：将查询和文档用单独的BERT编码器进行编码。匹配分数是两个序列嵌入的余弦相似度。双塔模型对于索引查询和文档向量表示更有效，并且通常用于第一阶段检索，而具有完整交叉注意力的单塔模型通常用于最终阶段的文档重新排序。在这项工作中，我们采用单塔模型完成中哈跨语言信息检索任务。

跨语言预训练语言模型能够同时对多种语言的文本进行编码。多语言BERT采用与BERT相同的模型结构和训练目标，但是在维基百科上对100多种语言进行了预训练。除了掩码语言建模（MLM）目标外，XLM模型还使用了翻译语言建模目标（TLM）进行预训练，以利用并行句子资源（如果可用）：一对平行句子被随机屏蔽，语言模型被挑战着根据本地上下文以及远程外语上下文来预测屏蔽的标记。XLM-RoBERTa通过整合更多的训练数据改进了XLM。还提出了两个额外的单词级和句子级任务来预训练Unicoder。对一系列单词级和句子级跨语言转移任务的评估表明，这些跨语言LM在将语言知识从高资源语言转移到低资源语言方面具有显著的效用。

### 1.3 图神经网络





## 2 方法





